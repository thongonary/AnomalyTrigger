{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mgpu-4-culture-plate-sm\u001b[0m  Tue Jul 16 15:48:12 2019\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 23'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 25'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n",
      "\u001b[0;36m[2]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 22'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n",
      "\u001b[0;36m[3]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 22'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n",
      "\u001b[0;36m[4]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 23'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n",
      "\u001b[0;36m[5]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 28'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n",
      "\u001b[0;36m[6]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 25'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m 3817\u001b[0m / \u001b[0;33m 8114\u001b[0m MB | \u001b[1;30mthong\u001b[0m(\u001b[0;33m3807M\u001b[0m)\n",
      "\u001b[0;36m[7]\u001b[0m \u001b[0;34mGeForce GTX 1080\u001b[0m |\u001b[0;31m 24'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m    0\u001b[0m / \u001b[0;33m 8114\u001b[0m MB |\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from glob import glob\n",
    "import sys, scipy\n",
    "from scipy.stats import chi2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import gpustat\n",
    "gpustat.print_gpustat()\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\" # Some versions of HDF5 require this\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2' # This is to choose which GPU to use\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader # \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "INPUT_LENGTH = 20 # number of particles to consider in 1 event\n",
    "INPUT_FEATURE = 4 # number of features. use pt, eta, phi, and pid\n",
    "BATCH_SIZE = 30\n",
    "PT_SCALE = 10\n",
    "MAX_EPOCH = 200\n",
    "# Maurizio's Delphes data\n",
    "# this is the location on the caltech machine. I copied the file to /eos/project/d/dshep/Thong_tmp/ on lxplus\n",
    "base_dir = '/bigdata/shared/L1AnomalyDetection/qcd_lepFilter_13TeV/' \n",
    "base_file = '/bigdata/shared/L1AnomalyDetection/qcd_all.npy'\n",
    "bsm_dir = '/bigdata/shared/L1AnomalyDetection/Ato4l_lepFilter_13TeV/'\n",
    "bsm_file = '/bigdata/shared/L1AnomalyDetection/Ato4l.npy'\n",
    "model_file = 'DelphesModel.torch'\n",
    "\n",
    "# particle is ordered: MET + 10 e + 10 mu + 20 jet\n",
    "# We will take 4 ele + 4 muon + 12 jets = 20 objects in total\n",
    "\n",
    "PARTICLE_TO_USE = np.asarray([False]*41)\n",
    "PARTICLE_TO_USE[1:5] = True # 4 ele\n",
    "PARTICLE_TO_USE[11:15] = True # 4 muon\n",
    "PARTICLE_TO_USE[21:33] = True # 12 jets\n",
    "print(sum(PARTICLE_TO_USE))\n",
    "FLAT_FEATURES = INPUT_LENGTH*INPUT_FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEventSequence(Dataset):\n",
    "    def __init__(self, data_x):\n",
    "        self.len = data_x.shape[0]\n",
    "        self.data_x = torch.from_numpy(data_x).float()\n",
    "        #self.data_y = torch.from_numpy(data_y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_x[idx].contiguous().view(FLAT_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_features, int(n_features*2/3)),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(int(n_features*2/3), int(n_features/3)),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(int(n_features/3), int(n_features*2/3)),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(int(n_features*2/3), n_features)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13780026, 20, 4)\n",
      "[ 7.1738086e+00 -2.1654021e-05 -7.8462181e-05  3.8649943e-01]\n",
      "[20.075266    0.6121493   0.6666415   0.87105507]\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "all_qcd = np.load(base_file).astype(np.float32)[:,PARTICLE_TO_USE,:]\n",
    "size_qcd = len(all_qcd)\n",
    "qcd_train = all_qcd[:int(size_qcd/2)]\n",
    "qcd_val = all_qcd[int(size_qcd/2):]\n",
    "print(all_qcd.shape)\n",
    "\n",
    "x_mean = np.mean(qcd_train.reshape((-1,4)), axis=0)\n",
    "x_std = np.std(qcd_train.reshape((-1,4)), axis=0)\n",
    "print(x_mean)\n",
    "print(x_std)\n",
    "\n",
    "qcd_train_norm = qcd_train\n",
    "qcd_val_norm = qcd_val\n",
    "\n",
    "# Normalize pt, eta, phi\n",
    "for i in range(3): \n",
    "    qcd_train_norm[:,:,i] = (qcd_train[:,:,i] - x_mean[i])/(x_std[i])\n",
    "    qcd_val_norm[:,:,i] = (qcd_val[:,:,i] - x_mean[i])/(x_std[i])\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(SimpleEventSequence(qcd_train_norm), \n",
    "                                    batch_size = BATCH_SIZE, shuffle=False,num_workers=3)\n",
    "val_loader = DataLoader(SimpleEventSequence(qcd_val_norm), \n",
    "                                    batch_size = BATCH_SIZE*10, shuffle=False,num_workers=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=80, out_features=53, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=53, out_features=26, bias=True)\n",
      "    (3): ReLU(inplace)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=26, out_features=53, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=53, out_features=80, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Trainable parameters: 11448\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Autoencoder(FLAT_FEATURES).cuda()\n",
    "print(model)\n",
    "trainablePars = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('\\nTrainable parameters:', trainablePars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train loss: 0.0641, Validation loss: 0.0321\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [2/200], Train loss: 0.0304, Validation loss: 0.0309\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [3/200], Train loss: 0.0299, Validation loss: 0.0307\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [4/200], Train loss: 0.0297, Validation loss: 0.0301\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [5/200], Train loss: 0.0296, Validation loss: 0.0307\n",
      "Stale = 1. Best loss = 0.03008725909999496\n",
      "Epoch [6/200], Train loss: 0.0295, Validation loss: 0.0298\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [7/200], Train loss: 0.0295, Validation loss: 0.0303\n",
      "Stale = 1. Best loss = 0.029823871334373923\n",
      "Epoch [8/200], Train loss: 0.0295, Validation loss: 0.0302\n",
      "Stale = 2. Best loss = 0.029823871334373923\n",
      "Epoch [9/200], Train loss: 0.0295, Validation loss: 0.0300\n",
      "Stale = 3. Best loss = 0.029823871334373923\n",
      "Epoch [10/200], Train loss: 0.0295, Validation loss: 0.0303\n",
      "Stale = 4. Best loss = 0.029823871334373923\n",
      "Epoch [11/200], Train loss: 0.0294, Validation loss: 0.0304\n",
      "Stale = 5. Best loss = 0.029823871334373923\n",
      "Epoch [12/200], Train loss: 0.0294, Validation loss: 0.0301\n",
      "Stale = 6. Best loss = 0.029823871334373923\n",
      "Epoch [13/200], Train loss: 0.0294, Validation loss: 0.0304\n",
      "Stale = 7. Best loss = 0.029823871334373923\n",
      "Epoch [14/200], Train loss: 0.0294, Validation loss: 0.0296\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [15/200], Train loss: 0.0294, Validation loss: 0.0301\n",
      "Stale = 1. Best loss = 0.0296110797496826\n",
      "Epoch [16/200], Train loss: 0.0294, Validation loss: 0.0296\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [17/200], Train loss: 0.0294, Validation loss: 0.0306\n",
      "Stale = 1. Best loss = 0.029574121587037153\n",
      "Epoch [18/200], Train loss: 0.0294, Validation loss: 0.0300\n",
      "Stale = 2. Best loss = 0.029574121587037153\n",
      "Epoch [19/200], Train loss: 0.0293, Validation loss: 0.0299\n",
      "Stale = 3. Best loss = 0.029574121587037153\n",
      "Epoch [20/200], Train loss: 0.0293, Validation loss: 0.0312\n",
      "Stale = 4. Best loss = 0.029574121587037153\n",
      "Epoch [21/200], Train loss: 0.0293, Validation loss: 0.0299\n",
      "Stale = 5. Best loss = 0.029574121587037153\n",
      "Epoch [22/200], Train loss: 0.0293, Validation loss: 0.0300\n",
      "Stale = 6. Best loss = 0.029574121587037153\n",
      "Epoch [23/200], Train loss: 0.0293, Validation loss: 0.0295\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [24/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 1. Best loss = 0.029460729627817754\n",
      "Epoch [25/200], Train loss: 0.0293, Validation loss: 0.0298\n",
      "Stale = 2. Best loss = 0.029460729627817754\n",
      "Epoch [26/200], Train loss: 0.0293, Validation loss: 0.0304\n",
      "Stale = 3. Best loss = 0.029460729627817754\n",
      "Epoch [27/200], Train loss: 0.0293, Validation loss: 0.0301\n",
      "Stale = 4. Best loss = 0.029460729627817754\n",
      "Epoch [28/200], Train loss: 0.0293, Validation loss: 0.0299\n",
      "Stale = 5. Best loss = 0.029460729627817754\n",
      "Epoch [29/200], Train loss: 0.0293, Validation loss: 0.0300\n",
      "Stale = 6. Best loss = 0.029460729627817754\n",
      "Epoch [30/200], Train loss: 0.0293, Validation loss: 0.0299\n",
      "Stale = 7. Best loss = 0.029460729627817754\n",
      "Epoch [31/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 8. Best loss = 0.029460729627817754\n",
      "Epoch [32/200], Train loss: 0.0293, Validation loss: 0.0299\n",
      "Stale = 9. Best loss = 0.029460729627817754\n",
      "Epoch [33/200], Train loss: 0.0293, Validation loss: 0.0295\n",
      "New best loss. Model saved in _best_DelphesModel.torch\n",
      "Epoch [34/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 1. Best loss = 0.02945250769194001\n",
      "Epoch [35/200], Train loss: 0.0293, Validation loss: 0.0298\n",
      "Stale = 2. Best loss = 0.02945250769194001\n",
      "Epoch [36/200], Train loss: 0.0293, Validation loss: 0.0298\n",
      "Stale = 3. Best loss = 0.02945250769194001\n",
      "Epoch [37/200], Train loss: 0.0293, Validation loss: 0.0299\n",
      "Stale = 4. Best loss = 0.02945250769194001\n",
      "Epoch [38/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 5. Best loss = 0.02945250769194001\n",
      "Epoch [39/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 6. Best loss = 0.02945250769194001\n",
      "Epoch [40/200], Train loss: 0.0293, Validation loss: 0.0303\n",
      "Stale = 7. Best loss = 0.02945250769194001\n",
      "Epoch [41/200], Train loss: 0.0293, Validation loss: 0.0300\n",
      "Stale = 8. Best loss = 0.02945250769194001\n",
      "Epoch [42/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 9. Best loss = 0.02945250769194001\n",
      "Epoch [43/200], Train loss: 0.0293, Validation loss: 0.0302\n",
      "Stale = 10. Best loss = 0.02945250769194001\n",
      "Epoch [44/200], Train loss: 0.0293, Validation loss: 0.0297\n",
      "Stale = 11. Best loss = 0.02945250769194001\n",
      "Epoch [45/200], Train loss: 0.0293, Validation loss: 0.0295\n",
      "Early stopped\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, \n",
    "                              mode='min',\n",
    "                              factor=0.3,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              threshold=1e-4,\n",
    "                              cooldown=2,\n",
    "                              min_lr=1e-7\n",
    "                             )\n",
    "\n",
    "train_loss = []\n",
    "loss_history = {'train': [], 'val': []}\n",
    "\n",
    "min_loss, stale_epochs = 1e6, 0\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    \n",
    "    batch_loss = []\n",
    "    # Training\n",
    "    model.train\n",
    "    for batch_idx, local_x in enumerate(train_loader):\n",
    "        local_x = Variable(local_x).float().cuda() \n",
    "        # I use an old version of Pytorch. For version > 0.4, feel free to remove Variable wrapper\n",
    "        x_prime = model(local_x)\n",
    "        loss = criterion(x_prime, local_x)\n",
    "        batch_loss.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    loss_history['train'].append(sum(batch_loss)/len(train_loader))\n",
    "\n",
    "    # Evaluation\n",
    "    batch_loss = []\n",
    "    model.eval()\n",
    "    \n",
    "    for batch_idx, local_x in enumerate(val_loader):\n",
    "        local_x = Variable(local_x, volatile=True).float().cuda() \n",
    "        # I use an old version of Pytorch. For version > 0.4, feel free to remove Variable wrapper\n",
    "        x_prime = model(local_x)\n",
    "        loss = criterion(x_prime, local_x)\n",
    "        batch_loss.append(loss.data[0])\n",
    "    \n",
    "    this_loss = sum(batch_loss)/len(val_loader)\n",
    "    loss_history['val'].append(this_loss)\n",
    "    \n",
    "    print('Epoch [{}/{}], Train loss: {:.4f}, Validation loss: {:.4f}'.format(epoch + 1, \n",
    "                                                                       MAX_EPOCH, \n",
    "                                                                       loss_history['train'][-1],\n",
    "                                                                       this_loss))\n",
    "    \n",
    "    if stale_epochs > 10:\n",
    "        print(\"Early stopped\")\n",
    "        break\n",
    "        \n",
    "    if this_loss < min_loss:\n",
    "        min_loss = this_loss\n",
    "        stale_epochs = 0\n",
    "        torch.save(model.state_dict(), '_best_'+model_file)\n",
    "        print(\"New best loss. Model saved in _best_{}\".format(model_file))\n",
    "    else:\n",
    "        stale_epochs += 1\n",
    "        print(\"Stale = {}. Best loss = {}\".format(stale_epochs, min_loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(FLAT_FEATURES).cuda()\n",
    "model.load_state_dict(torch.load('_best_{}'.format(model_file)))\n",
    "\n",
    "model.eval()\n",
    "volatile=True\n",
    "\n",
    "criterion = nn.L1Loss(reduce=False)\n",
    "sm_loss = np.array([])\n",
    "for batch_idx, local_x in enumerate(val_loader):\n",
    "    local_x = Variable(local_x, volatile=True).float().cuda() \n",
    "    # I use an old version of Pytorch. For version > 0.4, feel free to remove Variable wrapper\n",
    "    x_prime = model(local_x)\n",
    "    loss = torch.sum(criterion(x_prime, local_x), dim=1).view(-1,1).data.cpu().numpy()\n",
    "    sm_loss = np.concatenate((sm_loss, loss)) if sm_loss.size else loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
